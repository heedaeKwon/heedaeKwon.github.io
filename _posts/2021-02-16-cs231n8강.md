#                                                                                                 Localization and Detection


######                                                        우선 Localization입니다.  
######                                                        Localization을 먼저 쉽게 설명하자면 이미지의 오브젝트를 바운딩하는 것입니다. 다음 사진처럼 말입니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198451-f8cd4a00-715e-11eb-96ad-b996928e7ec5.PNG)
######                                                        만약 요기서 Classification을 하면 cat이라고 분류를 하는 것입니다. 
######                                                        localization의 output값은 (x,y,w,h)입니다. x,y값은 사진의 위치를 표시하고 w,h폭과 높이를 표시합니다
######                                                        쉽게 생각하면 xy평면에있는 직(or정)사각형이라 생각하면 될 것 같습니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198452-f965e080-715e-11eb-98e9-457c40101a03.PNG)
######                                                        이제 localization을 을 하는 방법을 보겠습니다
######                                                        먼저 첫 번째는 Localization을 Regression으로 간주하는것입니다.
######                                                        요기서 Regression이 뭐냐면 오차의 합이 최소가 되도록 하게하는 작업입니다.
######                                                        그럼 첫번재는 Classification model을 학습시키거나 ,Alex,VGG등 기존 네트워크에서 다운로드를합니다

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198454-f965e080-715e-11eb-8bc9-7f9cc2ab36a8.PNG)
######                                                        다음은 기존에 것에서 Regression head를 붙입니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198457-f9fe7700-715e-11eb-92cf-33b600b5cb21.PNG)
 ######                                                        3번째로는 Regression head를 오직 SGD와 L2 loss를 이용해 학습시킵니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198459-fa970d80-715e-11eb-826b-ea5b5c9a7ac2.PNG)
######                                                        마지막으로 테스트타임 때 2개의 heads를 사용합니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198460-fb2fa400-715e-11eb-91ed-1b1552351803.PNG) 
######                                                        Regression head에는 두가지 방법이있는데
######                                                        하나는 Class agnostic 이고 다른하나는 Class specific입니다
######                                                        Class agnostic은 말그대로 Class에 무관이므로 한개의 Box만 생성합니다. 그러나 Class specific은 신경을 쓰기 떄문에
######                                                        Box는 Class개수대로 생성이됩니다
     
     
                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198462-fb2fa400-715e-11eb-9f9a-6ef75a19705f.PNG)
######                                                        regression head는 conv layer 뒤쪽 또는 last FC layer 뒤쪽에 attach합니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198464-fbc83a80-715e-11eb-8824-a6aea6f76fc4.PNG)
######                                                        2번째는 Sliding Window입니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198465-fbc83a80-715e-11eb-9ed1-d7c8ba0674b3.PNG)
######                                                        말그대로 Window로 Sliding하는 것입니다.
######                                                        요기에 대표는 Overfeat이있는데

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198468-fc60d100-715e-11eb-92eb-2956367f0f6b.PNG)
######                                                        방법은 이 검은색 박스가 Sliding window를 할 것입니다. 이 때 image는 sliding window보다 커야합니다.
######                                                        이제 이 검은색Box로 Regression head를 이용하여서 Box의 좌표를 구해서 빨간색의 bounding box를 만들게 되고
######                                                        Classification head에 의해서 고양이로 분류하는 score를 구합니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198430-f4089600-715e-11eb-8a39-e26e379cec8a.PNG)
######                                                        요기서는 4번만 합니다. 이렇게 구한 4개의 bounding box와 score를 merge하여 단일 bounding box와 score가 최종값입니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198433-f539c300-715e-11eb-8822-93d6a927c93f.PNG)
######                                                        근데 실제는 4번이아니라 엄청 많이 Sliding window를 사용합니다. 이것을 bounding box로 연산을 하면 연산에 드는 비용이 너무 크게 되는 상황이 생깁니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198435-f5d25980-715e-11eb-9680-9a0e0b472597.PNG)
######                                                        그래서 FC -> CONV로 바꿔주는것입니다.
######                                                        요기부분을 저가 잘 이해를 한 것인지 모르겠는데 저가 이해한대로 한 번 설명을 해보겠습니다.
######                                                        요기 FC를 보면 4096x1의 FC가있습니다. 이것을 1x1 CONV를 지나쳐서 1024가되었는데 이렇게 될려면 
######                                                        4096이 depth가 되어야합니다. 그래서 표현을하면 1x1x4096으로 FC를 CONV로 간주합니다. 그럼 1x1x4096의 conv layer를 1024개 하면 1x1x1024가 됩니다.
######                                                        7강에서 1x1의 의미는 depth를 변화시켜 계산량 줄이는 것이라 설명했습니다. 이와같이 계산량을 줄여서 효율적으로 계산한다는 의미인거 같습니다.

#####                                                        자 다음은 Detection입니다. 저가 진짜 요기를 많이 봤는데 어렵기도 하고 그러니 또 강의를 듣거나 검색해서 설명을 볼 때 뇌를 끄고 보고 들은거 같습니다. 그래서 제대로 이해를 못했습니다.

######                                                        우선 Detection을 Localization처럼 Regression처럼 간주해도 되냐? 라 하면 아니다라 대답이나옵니다
######                                                        이유는 Detection은 object마다 이미지에따라 output개수가 달라지기 때문에 적합하지 않습니다.
######                                                        Detection은 그래서 Classification으로 간주합니다 다음사진처럼 검은색 박스안에 고양이는 있고 강아지는 없기때문에
######                                                        CAT은 YES 가 나왔고 DOG는 NO가 나왔습니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198436-f66af000-715e-11eb-8ca0-9f32d48cc304.PNG)
######                                                        근데 Classificiation기반의 Detection의 문제점은 object를 찾기위해 여러개의 window와 위치를 시도해야합니다.
######                                                        그래도 이 방법으로 하는게 또 해결책입니다. 단! CNN같은 경우는 무겁기때문에 이것은 피하는 것이 좋습니다.
######                                                        그러면 CNN의 경우는 어떻게해야하냐? 하면 바로 region proposal 입니다. 이게 무겁기 때문에 최대한 필요없는 부분을 보지않고

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198440-f66af000-715e-11eb-9cc5-f6df2c4ffa52.PNG)
######                                                        진짜 알짜배기같은 의심되는 지역만 보라는 것입니다.
######                                                        이렇게 되면 좋은점이 이 방법은 class다 집어치우고 그냥 대충 object가 드갈 거 같은 부분만 찾습니다 그러면 
######                                                        정확도는 무관하게 엄청 빠르게 실행이 됩니다.
######                                                        region proposal 의 방법중 하나는 Selective Search가 있습니다.
######                                                        Selective Search는 input이미지의 유사한 영역끼리 매우 세밀한 단위로 묶습니다. 이것을 점점 큰범위로 묶어서
######                                                        큰 범위로 box를 형성합니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198442-f7038680-715e-11eb-887d-3ee7a376975c.PNG)

####                                                        R-CNN
######                                                        자 요기서 진짜 저가 뭔 말을 하는지 잘 모르겠지만 좋게 봐주시면 감사하겠습니다.
######                                                        이 R-CNN은 Region Proposal과 CNN을 결합해서 R-CNN인 것입니다.
######                                                        순서는 먼저 input image를 Region Proposal방법으로 ROI(region of interest)를 검출합니다
######                                                        설명에서 보면 약 2000개를 뽑아 낸다고 합니다.


######                                                        이 2000개를 conv에 돌릴 것인데 그전에 conv에 맞게 crop하고 warping합니다.
######                                                        crop은 image사이즈를 conv에 맞게 자르는 것이고 warping은 그 잘리기 전 roi를 crop된 size에 맟추어 넣는 것이라 생가하면 되겠습니다
######                                                        그리고 conv에 적용합니다. 그렇게되면 BOX Regression head 와 Classification head가 있어서
######                                                        Regression head에서는 Bounding Box를 추출하고 CLassification head에서는 SVM을 이용해 Classify를 하게 됩니다.
######                                                        요기서 SVM은 Surrpot vector Machine의 준말로 분류를 위한 기준 선을 정의하는 것입니다.
######                                                        근데 이 R-CNN의 단점은 test time이 매우 느립니다. 2000개의 ROI를 FP로 CNN을 적용해야 한다고 설명되어있습니다
######                                                        이게 CNN과 classifier 와 bbox regression 세가지를 따로 학습해야하고 마지막으로 복잡합니다.
######                                                        평가는 maP로 합니다. 

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198445-f7038680-715e-11eb-9a07-f159c5adb6d4.PNG)
####                                                        maP는 mean average precision인데 해석하면 정확도 평균의 평균입니다.
######                                                        이야 진짜 이게 말이 너무 어렵습니다. 그럼 먼저  mean과 Average Precision으로 나누고 그리고 average 와 precision으로 나누겠습니다
######                                                        그럼 먼저 precision이 뭔지 알겠습니다. precision은 간단합니다. 이미지에서 object를 추출하는데 얼마나 정확하게 추출했냐는 것입니다.
######                                                        만약 고양이 10마리와 강아지 10마리가 있는 사진이 있다고 가정하겠습니다.
######                                                        precision은 요기서 고양이만을 추출하고싶다고 하면 precision의식은  옳게 추출되어야할것/(옳게 추출되어야할것+추출되면 안되는데 추출된것)입니다.
######                                                        그럼 precision을 높이려면 어떻게 해야하냐? 바로 bounding box를 엄청 생성해서 고양이를 찾으면 되는 것입니다.
######                                                        하지만 그렇게 되면 Recall이 낮아집니다. 와 갑자기 Recall은 뭔데 튀어나오냐 하실 것 같은데
######                                                        Recall은 뭐냐하면 고양이를 찾으려고 엄청 많은 bounding box를 생성한 개수 분에 옳게 검출한 것의 개수입니다.
######                                                        그럼 Recall값이 낮아지는게 신경쓰여서 분모개수를 줄이게되면 그만큼 옳게 추출한 것의 개수가 줄어들어 precision값이 줄어듭니다.
######                                                        자율주행으로 예를 들면 사람이있을 때 멈추는 시스템일 때 precision이 높으면 그만큼 검출하는 총 개수가 적기 때문에
######                                                        진짜 사람같은 사람 ex)(하나의 예시입니다.) 170대의 사람이라하면 170미만 또는 180이상 의 사람들은 사람으로 분류를 못하는 것과 같습니다.
######                                                        반면에 precision이 낮으면 그냥 뭐만하면 사람으로 간주해서 시도때도 없이 멈춥니다.
######                                                        그래서 이것을 절충하기위해 나온게 aP average precision이고
######                                                        maP는 이제 class간의 나온 ap들을 평균 내준것입니다.

####                                                        Fast R-CNN
######                                                        그래서 이 것을 보완하는 Fast R-CNN이 나왔습니다.
######                                                        Fast R-CNN은 R-CNN에서 처음 방법을 바꾸었습니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198447-f79c1d00-715e-11eb-885e-45f59f2a618f.PNG)
######                                                        먼저 input image를 CNN에 돌리고 추출된 feature map에서 ROI를 추출합니다.
######                                                        그리고 FC에 넘길때 ROI Pooling을해서 넘깁니다. 그리고 FC에서 classification head와 Regression head로 전달하고 classify 및 bounding box를 생성하게 됩니다. 
######                                                        그래가지고 먼저 2000개의 ROI를 CNN에돌리는 그런 불상사가 안일어나고
######                                                        SVM과 Regression의 결과가 CNN학습에 반영안되는 것과 복잡한것은
######                                                        end to end로 구성해서 한꺼번에 학습을 시킬 수 있어서 매우 효율적으로 되었습니다.
######                                                        Fast R-CNN에도 문제가 있습니다. 앞에서 보았던 Fast F-CNN의 이미지 당 test time은 Region Proposal time을 포함하지 않은 것으로 Selective Search와 같은 Region Proposal을 포함하게 되면 한 장당 2초 정도 걸리게 되어 Real-time Object Detection으로 사용하기 어려워 집니다. 

####                                                        Faster R-CNN

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198448-f834b380-715e-11eb-9a41-1420c02168a2.PNG)
######                                                        Faster R-CNN은 RPN(Region Proposal Network)을 구성합니다. 우선 input image는 Fast R-CNN과 같이
######                                                        CNN에 돌린 feature map을  RPN에서 적용하고 그 후는 Fast R-CNN과 같습니다.
######                                                        그럼 RPN은 어떻게 되냐 우선 CNN입니다. CNN인데 작은 CNN입니다. 3x3의 슬라이딩윈도우를 가지고 슬라이등을 적용하여 RPN을 생성한 것입니다.
######                                                        RPN은 각 영역이 object를 판단하고 Bounding Box와 Regression을 이용해 구해줍니다.

                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198449-f834b380-715e-11eb-81d7-b749a44ad89a.PNG)
######                                                        요기서 anchor box가 있는데 anchor box는 슬라이딩 윈도우 내의 존재하는 local window같은 것입니다.
######                                                        anchor box마다 비율이 다 제각각인데 그 각각의 비율에 포함되는 object만 인식한다 라고 생각하시면 됩니다.

####                                                        YOLO

######                                                        마지막으로 YOLO입니다. 이것은 그 기존의 You Only Live Once이 아닌 You Only Look Once 입니다. 
######                                                        YOLO는 이미지 내의 bounding box와 class probability를 single regression problem으로 간주하여, 이미지를 한 번 보는 것으로 object의 종류와 위치를 추측합니다
######                                                        이것의 장점은 간단한 처리과정으로 속도가 엄청빠릅니다.
######                                                        단점으로는 상대적으로 낮은 정확도가 되겠습니다.
                                                              ![logo](https://user-images.githubusercontent.com/68374734/108198450-f8cd4a00-715e-11eb-914e-a4d32cef111a.PNG)
