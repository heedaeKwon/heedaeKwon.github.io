# VGG

#### Introduction에서
###### VGG는 대량의 데이터 GPU의사용 conv로인해서 깊은 구조를 사용했습니다.
###### 이 때 conv는 3x3필터를 사용했고 그결과 accuracy가 올라간겄을 확인했습니다.

#### configuration에서는
###### input값은 224x224의 RGB이미지를 사용했고
###### 맥스풀링 레이어는 5개이오 2x2픽셀윈도우로 stride값은 2입니다.
###### FC레이어는 3개로 첫번째와 두번째는 4096개의 채널을 가지고 마지막은 1000개의 채널을 가지는 소프트맥스레이어입니다
###### Activation Fn은 ReLU를 사용합니다.
![logo](https://user-images.githubusercontent.com/68374734/108712075-9eb2f700-7559-11eb-91ce-d1ddeaea4be7.PNG)

###### 요기서 더 들어가면 여러개의 configuration이 있는데, A에서 E로갈수록 depth를 깊게 하였습니다.
![logo](https://user-images.githubusercontent.com/68374734/108712079-9fe42400-7559-11eb-9db4-59b91bdbeb97.PNG)
###### 처음 채널의 개수는 64개로 maxpooling layer를 지날때바다 512개의 채널이 될때까지 2배씩늘립니다.
###### 그리고 conv는 주로 3x3을 이용했는데 그 이유는 parameter를 감소 시켜 연산을 줄일 수 있기 때문입니다.
###### 예를 들면 7x7 conv는 3x3 conv 3개와 같은효과인데
###### 식으로 보면 (n-7)/1 + 1 = [((((n-3)/1+1)-3)/1+1)-3]/1 +1 과 같이 됩니다.
###### 그럼 파라미터의 개수를 비교하면 
###### 3(3^2C^2) = 27C^2
###### 7^2C^2 = 49C^2 
###### 즉, 22C^개의 parameter를 감소시킵니다.
###### 그리고 중간에 1x1 conv layer도 사용을 했는데, 그 이유는 1x1 conv를 거쳐가면서 ReLU함수가 적용되기 때문에 비선형성을 부여하는 용도로
###### 사용되었습니다

#### Training에서는
###### VGG는 Alexnet과 동일하게 training을 진행하였습니다. 
###### batch size =256 , momentum = 0.9 m , weight deacy = 0.00005 , epoch = 74 , learning rate =0.01
###### 이 때 learning rate는 3번 감소시키는데 감소시킬때마다 10배 감소시킵니다.
![logo](https://user-images.githubusercontent.com/68374734/108712081-a07cba80-7559-11eb-85ec-b7afbfce4596.PNG)

#### test time때는 이미지를 리스캐일 해주고
###### FC layer는 conv쪽으로 convert하고
###### data augment를 해서 테스트셋을 늘립니다.
###### experiment를 보면
###### data set imagenet에있는 1000개의 클래스를 사용하였고
###### training image는 130M개, validation image는  50K개 , testing image는  100K개입니다.
###### 평가는 top-1(예측이 잘못됫 이미지의 비율), top-5(예측된 범위에 정답이 없는 이미지의 비율)로 평가합니다.
![logo](https://user-images.githubusercontent.com/68374734/108712084-a1155100-7559-11eb-927b-0146fb37a109.PNG)


###### 첫 번째 결과표를 보면 A->E로 갈수록(깊어질수록) error rate가 낮아지는 것을 확인할 수 있습니다
![logo](https://user-images.githubusercontent.com/68374734/108712088-a1155100-7559-11eb-81ef-c9355cdb1712.PNG)
###### 두 번째 결과표를 보면 test이미지를 다양하게 resize해준 것들이 낮은 error rate를 보여주고 있습니다.
![logo](https://user-images.githubusercontent.com/68374734/108712091-a1ade780-7559-11eb-92bb-decac8e5c905.PNG)
###### 세 번째 결과표를 보면 모델 7개를 앙상을한것입니다. 이때 error rate는 7.5% 가나왔고 추후에 모델 2개를 앙상블하여 error rate 6.8%까지나왔습니다
![logo](https://user-images.githubusercontent.com/68374734/108712093-a1ade780-7559-11eb-81ae-a1077e03980c.PNG)

