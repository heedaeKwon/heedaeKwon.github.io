# DEEP Residual Learning for Image Recognition

#### Introduction

###### 기존의 연구들에서는 conv를 이용한 깊은 네트워크로 좋은 performance를 보여주었습니다.
###### 그래서 깊이에 대해 관심이 생겼도 과연 깊이가 결과에 도움을 주는건지에 대해 궁금증이 생겼습니다.
###### 확인결과는 degradation이라는 문제점이 발생이 됩니다.
###### dagradation은 뭐냐하면 depth가 증가함에 따라 accuracy가 saturated되어 degrade가 빨라지는 현상입니다.
###### overfiting현상과는 다른데 그 이유는 다음 사진을 보면 보통의 overfiting현상이면 train time에는 깊을수록
###### 낮은 error rate를 보이고 test time때 높은 error rate를 보여줍니다. 근데 degradation은
###### train과 test시 둘다 깊은 Network가 높은 error rate를 보여줍니다.
###### 그래서 이 문제를 해결하기 위해서 이 논문은 deep residual learning을 꺼냈습니다.

#### Related work

###### vlad image recognition과 Multy layer perceptron이 있습니다.

#### Residual Learning

![logo](https://user-images.githubusercontent.com/68374734/108978894-6f24fb80-76cd-11eb-94f4-2e26fcfafae2.PNG)
![logo]("https://user-images.githubusercontent.com/68374734/108978898-6fbd9200-76cd-11eb-9f32-398699fefc20.PNG)

###### 그럼 이 degradation을 해결할 residual learning을 알아보겠습니다. 
###### 이 방법은 few stacked layer mapping을 직접 학습하지 않고,
###### original mapping이 H(x)라면 H(x)-x 를 학습하는 것입니다. 
###### 이렇게 H(x)-x를 F(x)라 하면 F(x)를 학습하는 것이되고 original mapping은 F(x)+x로 재구성이 됩니다.
###### 그렇게 개별적인 optimaize가 아니기 때문에 쉽게 가능하게되었습니다.
###### 만약 x가 F(x)와 차원이 다를 걍우에는 Ws를 이용하여 차원을 맞추어줄 수 있습니다.

![logo](https://user-images.githubusercontent.com/68374734/108978912-721fec00-76cd-11eb-9a4c-e965993b531d.PNG)

###### 다음은 Architecture에있는 그림을 보겠습니다. 
###### 이 그림은 VGG , Plain net, Resnet을 비교하는 것입니다.

![logo](https://user-images.githubusercontent.com/68374734/108978901-70562880-76cd-11eb-881b-662631736168.PNG)

###### Plain은 VGG를 참고하여 만든것이고 모두 동일한 피쳐맵 사이즈를 가지기 위해서
###### layer들은 동일한 수의 filter를 가지게 합니다.
###### 만약 feature map size가 절반이 되면 filter는 2배가되어서 맞추어 주면됩니다.
###### ResNet은 Plain에 shortcut개념을 도입합니다.
###### 요기서 차원이다를 경우는 아까 말햇듯이 같은 차원으로 맞추어야하는데 차원이 증가할때 2가지 방법으로 맞춥니다
###### 하나는 0을 넣어서 padding을 합니다. 그렇게 되면 parameter의 증가없이 증가할수있고 또 아까말한거와같이
###### Ws를 사용하면 됩니다.

###### 그래서 experiment를 보면
![logo](https://user-images.githubusercontent.com/68374734/108978903-70eebf00-76cd-11eb-89d6-7311e7de1441.PNG)
![logo](https://user-images.githubusercontent.com/68374734/108978908-71875580-76cd-11eb-9e68-85a914be6b83.PNG)
###### Plain은 더 얕은 network가 더 좋은 결과가 나왔구 ResNet은 더 깊은 network가 더 좋은 결과를 보여주었습니다.
###### 그리고 Plain과 ResNet을 비교하면 Resnet이 더 좋은 결과가 나온것을 확인할 수 있습니다.
###### 그리고 다음도 보시면 제일깊은 ResNet 152가 제일 좋은 결과가 나온 것을 확인할 수 있습니다.
![logo](https://user-images.githubusercontent.com/68374734/108978911-71875580-76cd-11eb-9b8c-4ce9343c04eb.PNG)

