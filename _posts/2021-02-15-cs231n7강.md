# Convolution Neural Network(CNN)

###### 자 이번에는 CNN을 하는 방법에 대해서 알아보겠다.
###### 요기 32x32x3 image가 있다 이것을 5x5x3필터로 stride값은 1로 해서 convolution을 하겠다
###### 중요한 것은 필터는 input image의 depth와 같아야한다. stride는 값은 몇칸을 움직이는지를 뜻한다.
###### 그렇게 필터를 거치면 28x28x1이라는 activation map이 생긴다 만약 filter가 2개면 activation map이 2개생긴다
###### 1개의 필터당 1개의 activation map이 생기는 것이다. 만약 필터가 6개라면? 아마 6개의 activation map이 생길 것이다
###### 그렇게 되면 28x28x6으로 다시 표현을 할 수있다. 또 이것을 conv하려면 필터의 depth는 FxFx'6'이 되어야 할 것이다.
###### 그럼 28은 어떻게 된것인가? 간단하다. 5x5필터가 1칸씩해서 총 28칸을 같다는 것이다. 만약 stride값을 3으로했으면
###### activation map은 아마 10x10x1이 되었을 것이다. 그럼 이 것을 식으로 일반화를 해보면
###### NxNx'D'의 인풋값을 FxFx'D' 의 K개의필터로 stride S값으로 conv를 하게 되면
###### 생성되는 activation map은 {(N-F)/S + 1} x {(N-F)/S + 1} x K 의 값으로 될 것이다.
###### 근데 conv를 계속하면 보시다시피 값이 줄어드는 현상이 보인다. 이렇게 되면 만약 깊어질시에 conv를 계속돌리면
###### 생성되는 activation map은 계속작아져서 나중에는 conv를 못하게 된다. 이것을 방지하기 위해 'paddin'이 생겼다
###### paddin은 간단하다 0의 값을 추가하는 것이다 7x7에 0값으로 1층을 만들면 9x9가 될것이다 이것을 만약 3x3 stride 1로
###### conv를 하면 7x7의 값으로 size보존이 이루어진다
###### 1x1의 conv는 어떨까? 이것은 2차원으로보면 어차피 같은 값이 나오기때문에 의미가 없어보인다. 하지만 image는 3차원이므로
###### 
###### 
###### 
###### 
###### 
###### 
###### 
###### 
###### 
###### 
###### 
